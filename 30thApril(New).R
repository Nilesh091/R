
  
  install.packages("tm")
install.packages("wordcloud")

library(tm)
library(wordcloud)

#setwd("C:/Users/DC/Desktop/comments.csv")
comm<-read.csv(file.choose())
View(comm)
#comm <-read.csv("comments.csv",header=TRUE)

#Corpus is an R text processing package with full support for international
#text (Unicode).
#It includes functions for reading data from newline-delimited JSON files,
#for normalizing and tokenizing text, for searching for term occurrences,
#and for computing term occurrence frequencies

install.packages("corpustools")
library(corpustools)

corpus<- Corpus(VectorSource(comm$Comments))

?VectorSource
#A vector source interprets each element of the vector x as a document.

corpus[[1]][1]

#clean Text
# 1. Convert entire text into lower case
corpus <- tm_map(corpus,content_transformer(function(x)iconv(x,"latin1","ASCII",
                                                             sub="")))

# 2. Remove the numbers
corpus<- tm_map(corpus, removeNumbers)

# 3. Remove common stopwords of english
corpus<- tm_map(corpus, removeWords, stopwords("english"))
corpus[[1]][1]

# 4. Remove Punctuations

corpus<- tm_map(corpus, removePunctuation)

# 5. Eliminate extra white space generated by removal

corpus<- tm_map(corpus, stripWhitespace)

# 6. Stemming texts
corpus<- tm_map(corpus, stemDocument)
corpus[[1]][1]

# 7. Remove additional stopwords
corpus<- tm_map(corpus, removeWords,c("get","told","gave","took","can","give"))
corpus[[1]][1]

# 8. create TDM
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word=names(v),freq=v)

#A document-term matrix is a mathematical matrix that describes the frequency of
#terms that occur in a collection of documents

# create wordcloud
wordcloud(d$word, d$freq, random.order = FALSE, rot.per = 0.3, scale = c(4,.5), max.words=101,colors=brewer.pal(8,"Dark2"))

#give title
title(main="word cloud - unigram", font.main = 1, cex.main = 1.5)

11:00 AM


***************************Heat Maps************************ 
  #Heat maps shows where values has higher magnitude and where values has less magnitude.
  #dark color indicate higher magnitude and light colors indicate less magnitude.
  #Syntax
  
  #heatmap(x, scale, na.rm, col, labRow, labCol, main)
  
  #x is the numeric matrix containing the values being used in creating the heat map.
  #col is the color palette to be used by the heat map.
  #na.rm is a logical value that determines whether NA values should be removed.
  #labRow is a vector of the row labels and is rownames(x) by default.
  #labCol is a vector of the column labels and is colnames(x) by default.
#main is the name of the heat map.
#scale is used to determine where the values are to be centered and scaled in.
#It can have the values of “row”, “column”, or “none” and is “row” by default.

str(mtcars)

rownames(mtcars)
colnames(mtcars)

#convert data frame into matrix

data <- as.matrix(mtcars)
heatmap(data,scale="column",col=heat.colors(256), main = "Characterstics of car models",Rowv = NA,Colv = NA)

#heatmap with enhanced colours

heatmap(data,scale="column",col=rainbow(length(data)), main = "Characterstics of car models",Rowv = NA,Colv = NA)